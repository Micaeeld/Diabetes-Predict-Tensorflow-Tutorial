{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d985dfd",
   "metadata": {},
   "source": [
    "# ü©∫ Diabetes Classification Using TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6399299",
   "metadata": {},
   "source": [
    "- This is a code example to create a classification model using TensorFlow to determine if a person has diabetes or not.\n",
    "\n",
    "- The notebook contains the explanation of each line and why to do it.\n",
    "\n",
    "- The model will be trained based on a dataset that contains information about different characteristics of people."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391467a6",
   "metadata": {},
   "source": [
    "# üìö Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80d8c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from autoviz.classify_method import data_cleaning_suggestions\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c257dc",
   "metadata": {},
   "source": [
    "- **pandas** and **numpy** are popular libraries for data manipulation and analysis\n",
    "\n",
    "\n",
    "- **autoviz.classify_method** is used to provide suggestions for data cleaning, such as handling missing values and encoding labels\n",
    "\n",
    "\n",
    "- **sklearn.preprocessing.LabelEncoder** is used to encode categorical labels into numeric values\n",
    "\n",
    "\n",
    "- **sklearn.preprocessing.StandardScaler** is used to standardize dataset resources\n",
    "\n",
    "\n",
    "- **sklearn.model_selection.train_test_split** is used to split the dataset into training and test sets\n",
    "\n",
    "\n",
    "- **tensorflow** is a popular framework for building and training machine learning models\n",
    "\n",
    "\n",
    "- **tensorflow.keras.Sequential** is a sequential model where the layers are linearly stacked\n",
    "\n",
    "\n",
    "- **tensorflow.keras.layers.Dense** defines a dense (fully connected) layer of the neural network\n",
    "\n",
    "\n",
    "- **tensorflow.keras.layers.Dropout** is used to add dropout layers to avoid overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606dc0f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9819634f",
   "metadata": {},
   "source": [
    "# üìÅ Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "968966c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>smoking_history</th>\n",
       "      <th>bmi</th>\n",
       "      <th>HbA1c_level</th>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <th>diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>never</td>\n",
       "      <td>25.19</td>\n",
       "      <td>6.6</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Info</td>\n",
       "      <td>27.32</td>\n",
       "      <td>6.6</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>never</td>\n",
       "      <td>27.32</td>\n",
       "      <td>5.7</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>current</td>\n",
       "      <td>23.45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>current</td>\n",
       "      <td>20.14</td>\n",
       "      <td>4.8</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease smoking_history    bmi  \\\n",
       "0  Female  80.0             0              1           never  25.19   \n",
       "1  Female  54.0             0              0         No Info  27.32   \n",
       "2    Male  28.0             0              0           never  27.32   \n",
       "3  Female  36.0             0              0         current  23.45   \n",
       "4    Male  76.0             1              1         current  20.14   \n",
       "\n",
       "   HbA1c_level  blood_glucose_level  diabetes  \n",
       "0          6.6                  140         0  \n",
       "1          6.6                   80         0  \n",
       "2          5.7                  158         0  \n",
       "3          5.0                  155         0  \n",
       "4          4.8                  155         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('data/diabetes_prediction_dataset.csv')\n",
    "\n",
    "# Showing 5 rows from the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622a136",
   "metadata": {},
   "source": [
    "- The diabetes dataset is read from the 'data/diabetes_prediction_dataset.csv' file using the pd.read_csv function;\n",
    "df.head() is used to view the first rows of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c67c082",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c865c",
   "metadata": {},
   "source": [
    "# üßÆ Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b54eedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>41.885856</td>\n",
       "      <td>22.516840</td>\n",
       "      <td>0.08</td>\n",
       "      <td>24.00</td>\n",
       "      <td>43.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypertension</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.263150</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>0.194593</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>27.320767</td>\n",
       "      <td>6.636783</td>\n",
       "      <td>10.01</td>\n",
       "      <td>23.63</td>\n",
       "      <td>27.32</td>\n",
       "      <td>29.58</td>\n",
       "      <td>95.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HbA1c_level</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>5.527507</td>\n",
       "      <td>1.070672</td>\n",
       "      <td>3.50</td>\n",
       "      <td>4.80</td>\n",
       "      <td>5.80</td>\n",
       "      <td>6.20</td>\n",
       "      <td>9.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blood_glucose_level</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>138.058060</td>\n",
       "      <td>40.708136</td>\n",
       "      <td>80.00</td>\n",
       "      <td>100.00</td>\n",
       "      <td>140.00</td>\n",
       "      <td>159.00</td>\n",
       "      <td>300.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>0.278883</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count        mean        std    min     25%     50%  \\\n",
       "age                  100000.0   41.885856  22.516840   0.08   24.00   43.00   \n",
       "hypertension         100000.0    0.074850   0.263150   0.00    0.00    0.00   \n",
       "heart_disease        100000.0    0.039420   0.194593   0.00    0.00    0.00   \n",
       "bmi                  100000.0   27.320767   6.636783  10.01   23.63   27.32   \n",
       "HbA1c_level          100000.0    5.527507   1.070672   3.50    4.80    5.80   \n",
       "blood_glucose_level  100000.0  138.058060  40.708136  80.00  100.00  140.00   \n",
       "diabetes             100000.0    0.085000   0.278883   0.00    0.00    0.00   \n",
       "\n",
       "                        75%     max  \n",
       "age                   60.00   80.00  \n",
       "hypertension           0.00    1.00  \n",
       "heart_disease          0.00    1.00  \n",
       "bmi                   29.58   95.69  \n",
       "HbA1c_level            6.20    9.00  \n",
       "blood_glucose_level  159.00  300.00  \n",
       "diabetes               0.00    1.00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed142a0c",
   "metadata": {},
   "source": [
    "- **df.describe().T** calculates descriptive statistics for each column of the dataset, transposing the result to display the statistics in tabular format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94aed02",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea6eca8",
   "metadata": {},
   "source": [
    "# üßπ Data cleaning suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88e7e6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning improvement suggestions. Complete them before proceeding to ML modeling.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_96a58_row0_col0, #T_96a58_row0_col4, #T_96a58_row4_col5 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_96a58_row0_col1, #T_96a58_row0_col6, #T_96a58_row1_col1, #T_96a58_row1_col6, #T_96a58_row2_col1, #T_96a58_row2_col6, #T_96a58_row3_col1, #T_96a58_row3_col6, #T_96a58_row4_col1, #T_96a58_row4_col6, #T_96a58_row5_col1, #T_96a58_row5_col6, #T_96a58_row6_col1, #T_96a58_row6_col6, #T_96a58_row7_col1, #T_96a58_row7_col6, #T_96a58_row8_col1, #T_96a58_row8_col6 {\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_96a58_row0_col2, #T_96a58_row0_col3, #T_96a58_row0_col5, #T_96a58_row1_col2, #T_96a58_row1_col3, #T_96a58_row1_col5, #T_96a58_row2_col0, #T_96a58_row2_col2, #T_96a58_row2_col3, #T_96a58_row2_col4, #T_96a58_row2_col5, #T_96a58_row3_col0, #T_96a58_row3_col2, #T_96a58_row3_col3, #T_96a58_row3_col4, #T_96a58_row3_col5, #T_96a58_row4_col0, #T_96a58_row4_col2, #T_96a58_row4_col3, #T_96a58_row4_col4, #T_96a58_row5_col0, #T_96a58_row5_col2, #T_96a58_row5_col3, #T_96a58_row5_col4, #T_96a58_row6_col0, #T_96a58_row6_col2, #T_96a58_row6_col3, #T_96a58_row6_col4, #T_96a58_row6_col5, #T_96a58_row7_col0, #T_96a58_row7_col2, #T_96a58_row7_col3, #T_96a58_row7_col4, #T_96a58_row7_col5, #T_96a58_row8_col0, #T_96a58_row8_col2, #T_96a58_row8_col3, #T_96a58_row8_col4, #T_96a58_row8_col5 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_96a58_row1_col0, #T_96a58_row1_col4 {\n",
       "  background-color: #fff1ea;\n",
       "  color: #000000;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "#T_96a58_row5_col5 {\n",
       "  background-color: #fff4ef;\n",
       "  color: #000000;\n",
       "  font-family: Segoe UI;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_96a58\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_96a58_level0_col0\" class=\"col_heading level0 col0\" >Nuniques</th>\n",
       "      <th id=\"T_96a58_level0_col1\" class=\"col_heading level0 col1\" >dtype</th>\n",
       "      <th id=\"T_96a58_level0_col2\" class=\"col_heading level0 col2\" >Nulls</th>\n",
       "      <th id=\"T_96a58_level0_col3\" class=\"col_heading level0 col3\" >Nullpercent</th>\n",
       "      <th id=\"T_96a58_level0_col4\" class=\"col_heading level0 col4\" >NuniquePercent</th>\n",
       "      <th id=\"T_96a58_level0_col5\" class=\"col_heading level0 col5\" >Value counts Min</th>\n",
       "      <th id=\"T_96a58_level0_col6\" class=\"col_heading level0 col6\" >Data cleaning improvement suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row0\" class=\"row_heading level0 row0\" >bmi</th>\n",
       "      <td id=\"T_96a58_row0_col0\" class=\"data row0 col0\" >4247</td>\n",
       "      <td id=\"T_96a58_row0_col1\" class=\"data row0 col1\" >float64</td>\n",
       "      <td id=\"T_96a58_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row0_col3\" class=\"data row0 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row0_col4\" class=\"data row0 col4\" >4.247000</td>\n",
       "      <td id=\"T_96a58_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_96a58_row0_col6\" class=\"data row0 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row1\" class=\"row_heading level0 row1\" >age</th>\n",
       "      <td id=\"T_96a58_row1_col0\" class=\"data row1 col0\" >102</td>\n",
       "      <td id=\"T_96a58_row1_col1\" class=\"data row1 col1\" >float64</td>\n",
       "      <td id=\"T_96a58_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row1_col3\" class=\"data row1 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row1_col4\" class=\"data row1 col4\" >0.102000</td>\n",
       "      <td id=\"T_96a58_row1_col5\" class=\"data row1 col5\" >0</td>\n",
       "      <td id=\"T_96a58_row1_col6\" class=\"data row1 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row2\" class=\"row_heading level0 row2\" >HbA1c_level</th>\n",
       "      <td id=\"T_96a58_row2_col0\" class=\"data row2 col0\" >18</td>\n",
       "      <td id=\"T_96a58_row2_col1\" class=\"data row2 col1\" >float64</td>\n",
       "      <td id=\"T_96a58_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row2_col3\" class=\"data row2 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row2_col4\" class=\"data row2 col4\" >0.018000</td>\n",
       "      <td id=\"T_96a58_row2_col5\" class=\"data row2 col5\" >0</td>\n",
       "      <td id=\"T_96a58_row2_col6\" class=\"data row2 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row3\" class=\"row_heading level0 row3\" >blood_glucose_level</th>\n",
       "      <td id=\"T_96a58_row3_col0\" class=\"data row3 col0\" >18</td>\n",
       "      <td id=\"T_96a58_row3_col1\" class=\"data row3 col1\" >int64</td>\n",
       "      <td id=\"T_96a58_row3_col2\" class=\"data row3 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row3_col3\" class=\"data row3 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row3_col4\" class=\"data row3 col4\" >0.018000</td>\n",
       "      <td id=\"T_96a58_row3_col5\" class=\"data row3 col5\" >0</td>\n",
       "      <td id=\"T_96a58_row3_col6\" class=\"data row3 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row4\" class=\"row_heading level0 row4\" >smoking_history</th>\n",
       "      <td id=\"T_96a58_row4_col0\" class=\"data row4 col0\" >6</td>\n",
       "      <td id=\"T_96a58_row4_col1\" class=\"data row4 col1\" >object</td>\n",
       "      <td id=\"T_96a58_row4_col2\" class=\"data row4 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row4_col3\" class=\"data row4 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row4_col4\" class=\"data row4 col4\" >0.006000</td>\n",
       "      <td id=\"T_96a58_row4_col5\" class=\"data row4 col5\" >4004</td>\n",
       "      <td id=\"T_96a58_row4_col6\" class=\"data row4 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row5\" class=\"row_heading level0 row5\" >gender</th>\n",
       "      <td id=\"T_96a58_row5_col0\" class=\"data row5 col0\" >3</td>\n",
       "      <td id=\"T_96a58_row5_col1\" class=\"data row5 col1\" >object</td>\n",
       "      <td id=\"T_96a58_row5_col2\" class=\"data row5 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row5_col3\" class=\"data row5 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row5_col4\" class=\"data row5 col4\" >0.003000</td>\n",
       "      <td id=\"T_96a58_row5_col5\" class=\"data row5 col5\" >18</td>\n",
       "      <td id=\"T_96a58_row5_col6\" class=\"data row5 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row6\" class=\"row_heading level0 row6\" >hypertension</th>\n",
       "      <td id=\"T_96a58_row6_col0\" class=\"data row6 col0\" >2</td>\n",
       "      <td id=\"T_96a58_row6_col1\" class=\"data row6 col1\" >int64</td>\n",
       "      <td id=\"T_96a58_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row6_col3\" class=\"data row6 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row6_col4\" class=\"data row6 col4\" >0.002000</td>\n",
       "      <td id=\"T_96a58_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_96a58_row6_col6\" class=\"data row6 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row7\" class=\"row_heading level0 row7\" >heart_disease</th>\n",
       "      <td id=\"T_96a58_row7_col0\" class=\"data row7 col0\" >2</td>\n",
       "      <td id=\"T_96a58_row7_col1\" class=\"data row7 col1\" >int64</td>\n",
       "      <td id=\"T_96a58_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row7_col3\" class=\"data row7 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row7_col4\" class=\"data row7 col4\" >0.002000</td>\n",
       "      <td id=\"T_96a58_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_96a58_row7_col6\" class=\"data row7 col6\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_96a58_level0_row8\" class=\"row_heading level0 row8\" >diabetes</th>\n",
       "      <td id=\"T_96a58_row8_col0\" class=\"data row8 col0\" >2</td>\n",
       "      <td id=\"T_96a58_row8_col1\" class=\"data row8 col1\" >int64</td>\n",
       "      <td id=\"T_96a58_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_96a58_row8_col3\" class=\"data row8 col3\" >0.000000</td>\n",
       "      <td id=\"T_96a58_row8_col4\" class=\"data row8 col4\" >0.002000</td>\n",
       "      <td id=\"T_96a58_row8_col5\" class=\"data row8 col5\" >0</td>\n",
       "      <td id=\"T_96a58_row8_col6\" class=\"data row8 col6\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2101c1098e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data cleaning suggestions\n",
    "data_cleaning_suggestions(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b87e84a",
   "metadata": {},
   "source": [
    "- **data_cleaning_suggestions(df)** is a function that provides data cleaning suggestions based on dataset characteristics. This function probably uses techniques such as identifying missing values, removing duplicates, handling outliers, encoding labels, among others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0928981f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda371ff",
   "metadata": {},
   "source": [
    "# üß¨ Convert categorical columns to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "738f09ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "list_str = ['gender', 'smoking_history']\n",
    "for c in list_str:\n",
    "    df[c] = le.fit_transform(df[c])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9905bb71",
   "metadata": {},
   "source": [
    "- In this part of the code, we are using the LabelEncoder to transform the categorical columns into numerical ones. LabelEncoder is a class in the sklearn.preprocessing module that transforms categorical labels into numbers. This transformation is necessary because many machine learning algorithms only work with numerical data. In the example, we are turning the 'gender' and 'smoking_history' columns of the df dataframe into numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facd4070",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d6ea9",
   "metadata": {},
   "source": [
    "# ‚úÇÔ∏è Splitting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0653793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('diabetes', axis = 1)\n",
    "y = df['diabetes']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d351880",
   "metadata": {},
   "source": [
    "- Here, we are splitting the data into training and testing sets using the train_test_split function of the sklearn.model_selection module. This function splits the data at a specific ratio (in this case, 80% for training and 20% for testing) and ensures that the split is done randomly, using the value of random_state to control randomness.\n",
    "\n",
    "- Set X contains all the columns of the dataframe, except the 'diabetes' column, which is the target variable we want to predict. Set y contains only the 'diabetes' column. The sets xtrain and ytrain are used to train the model, while xtest and ytest are used to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0eec9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8679f96c",
   "metadata": {},
   "source": [
    "# üìè Standardizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce1b14a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "xtrain = scaler.fit_transform(xtrain)\n",
    "xtest = scaler.transform(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240e55d",
   "metadata": {},
   "source": [
    "- Here, we are using the StandardScaler from the sklearn.preprocessing module to standardize numerical data. Patterning is a common technique when preparing data for training machine learning models. It transforms the data so that the mean is 0 and the standard deviation is 1, ensuring that all features have the same scale. This is important because many machine learning algorithms are sensitive to the scale of the data.\n",
    "\n",
    "- First, we create an instance of StandardScaler called scaler. We then use the fit_transform method to compute the standardization statistics (mean and standard deviation) from the xtrain training set, and then apply the transform to the training and test sets using the transform method. This ensures that the same standardization is applied to both sets, using the statistics computed on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d917519c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d55d7c",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd84d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, activation = 'relu', input_shape = (xtrain.shape[1],)),\n",
    "    Dropout(0.1),\n",
    "    Dense(32, activation = 'relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation = 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac257f7",
   "metadata": {},
   "source": [
    "In this piece of code, we are creating a neural network model using TensorFlow. The model is defined as a sequence of stacked layers. Here is an explanation of each part:\n",
    "\n",
    "- **Dense(32, activation='relu', input_shape=(xtrain.shape[1],)):** This line creates a dense layer with 32 units (neurons) and ReLU activation function. The layer receives as input a shape tensor (xtrain.shape[1],), which corresponds to the format of the input data of the training set. This layer is the first layer of the model, so we specify the input format.\n",
    "\n",
    "\n",
    "- **Dropout(0.1):** This line adds a dropout layer with a rate of 0.1. Dropout is a regularization technique that helps prevent overfitting by randomly deactivating a fraction of neurons during training.\n",
    "\n",
    "\n",
    "- **Dense(32, activation='relu'):** This line creates another dense layer with 32 units and ReLU activation function. This is the second layer of the model, no need to specify the input format as the output from the previous layer is used as input.\n",
    "\n",
    "\n",
    "- **Dropout(0.5):** This line adds a second dropout layer with a rate of 0.5.\n",
    "\n",
    "\n",
    "- **Dense(1, activation='sigmoid'):** This line creates the output layer of the model with a single neuron and sigmoid activation function. This layer is responsible for producing the binary output of the model (0 or 1), indicating the target class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe49863",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c34e3",
   "metadata": {},
   "source": [
    "# üßæ Model compilation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f28d8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                288       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,377\n",
      "Trainable params: 1,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a497c9ff",
   "metadata": {},
   "source": [
    "After creating the model, we need to compile it before training it. On the first line, we are setting the model build options:\n",
    "\n",
    "- **loss='binary_crossentropy':** We use the binary cross entropy as the loss function. This loss function is suitable for binary classification problems, where we are trying to predict one of two classes.\n",
    "\n",
    "\n",
    "- **optimizer='adam':** The Adam optimizer will be used to adjust model weights during training. Adam is a popular optimization algorithm that relies on stochastic gradient descent methods.\n",
    "\n",
    "\n",
    "- **metrics=['accuracy']:** In addition to the loss function, we also want to track the accuracy metric during model training and evaluation. Accuracy is a common measure for evaluating classification model performance.\n",
    "\n",
    "On the second line, we are printing a model summary, which displays the architecture of the neural network in tabular form. The summary includes information about the input and output format of each layer, the total number of trainable parameters, and the overall model summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964d290",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b04c5d",
   "metadata": {},
   "source": [
    "# üèãÔ∏è Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d04ef235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5000/5000 [==============================] - 9s 1ms/step - loss: 0.1382 - accuracy: 0.9511 - val_loss: 0.1090 - val_accuracy: 0.9618\n",
      "Epoch 2/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.1084 - accuracy: 0.9626 - val_loss: 0.0952 - val_accuracy: 0.9676\n",
      "Epoch 3/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0982 - accuracy: 0.9666 - val_loss: 0.0875 - val_accuracy: 0.9708\n",
      "Epoch 4/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0924 - accuracy: 0.9685 - val_loss: 0.0858 - val_accuracy: 0.9712\n",
      "Epoch 5/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0900 - accuracy: 0.9696 - val_loss: 0.0858 - val_accuracy: 0.9711\n",
      "Epoch 6/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0893 - accuracy: 0.9696 - val_loss: 0.0840 - val_accuracy: 0.9720\n",
      "Epoch 7/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0878 - accuracy: 0.9703 - val_loss: 0.0846 - val_accuracy: 0.9718\n",
      "Epoch 8/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0878 - accuracy: 0.9705 - val_loss: 0.0831 - val_accuracy: 0.9720\n",
      "Epoch 9/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0877 - accuracy: 0.9705 - val_loss: 0.0841 - val_accuracy: 0.9714\n",
      "Epoch 10/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0866 - accuracy: 0.9706 - val_loss: 0.0832 - val_accuracy: 0.9722\n",
      "Epoch 11/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0864 - accuracy: 0.9707 - val_loss: 0.0844 - val_accuracy: 0.9714\n",
      "Epoch 12/20\n",
      "5000/5000 [==============================] - 8s 2ms/step - loss: 0.0863 - accuracy: 0.9710 - val_loss: 0.0841 - val_accuracy: 0.9714\n",
      "Epoch 13/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0862 - accuracy: 0.9707 - val_loss: 0.0825 - val_accuracy: 0.9722\n",
      "Epoch 14/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0855 - accuracy: 0.9708 - val_loss: 0.0875 - val_accuracy: 0.9689\n",
      "Epoch 15/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0854 - accuracy: 0.9709 - val_loss: 0.0828 - val_accuracy: 0.9718\n",
      "Epoch 16/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0853 - accuracy: 0.9711 - val_loss: 0.0820 - val_accuracy: 0.9724\n",
      "Epoch 17/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0851 - accuracy: 0.9711 - val_loss: 0.0823 - val_accuracy: 0.9721\n",
      "Epoch 18/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0848 - accuracy: 0.9711 - val_loss: 0.0820 - val_accuracy: 0.9723\n",
      "Epoch 19/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0852 - accuracy: 0.9710 - val_loss: 0.0824 - val_accuracy: 0.9722\n",
      "Epoch 20/20\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.0847 - accuracy: 0.9711 - val_loss: 0.0820 - val_accuracy: 0.9723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2101cae17f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain, ytrain, epochs = 20, batch_size = 16, validation_data = (xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e610a5",
   "metadata": {},
   "source": [
    "In this part of the code, we are training the neural network model. Here is an explanation of the different parts:\n",
    "\n",
    "- **xtrain** and **ytrain** are the training data, where xtrain contains the resources (inputs) and ytrain contains the corresponding labels (outputs). This data is used to adjust model weights during training.\n",
    "\n",
    "\n",
    "- **epochs** is the number of times the model will go through the entire training set. Each epoch consists of a cycle of going through the training data and adjusting the model weights.\n",
    "\n",
    "\n",
    "- **batch_size** is the number of training examples used in a single iteration. The training set is divided into smaller batches and adjustment of model weights is performed after each batch.\n",
    "\n",
    "\n",
    "- **validation_data = (xtest, ytest)** specifies the validation data to be used during training. This data is used to evaluate the model's performance on an independent dataset during training. xtest are the test resources and ytest are the corresponding labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9cba3b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd748d9f",
   "metadata": {},
   "source": [
    "# üìã Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62c1ee49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 1s 1ms/step - loss: 0.0820 - accuracy: 0.9723\n",
      "Test loss: 0.08\n",
      "Test accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(xtest, ytest)\n",
    "print(f'Test loss: {loss:.2f}')\n",
    "print(f'Test accuracy: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb48c4",
   "metadata": {},
   "source": [
    "In this part of the code, we are evaluating the performance of the trained model using the test data. Here is an explanation of the different parts:\n",
    "\n",
    "- **model.evaluate(xtest, ytest)** calculates the loss and accuracy of the model in relation to the test data. Loss is a measure of how well the model is performing the task, while accuracy is the proportion of test examples correctly classified by the model.\n",
    "\n",
    "\n",
    "- **loss** is the loss calculated by the model on the test data.\n",
    "\n",
    "\n",
    "- **accuracy** is the accuracy calculated by the model on the test data.\n",
    "\n",
    "\n",
    "- **print(f'Test loss: {loss}')** prints the loss calculated during the evaluation of the test data.\n",
    "\n",
    "\n",
    "- **print(f'Test accuracy: {accuracy}')** prints the accuracy calculated during the evaluation of the test data.\n",
    "\n",
    "This information is useful for understanding the performance of the trained model and evaluating its ability to generalize to previously unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dc0a26",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20101f32",
   "metadata": {},
   "source": [
    "# üòÅ Thank you! Feel free to criticize! üëãüèº"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd09575",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
